{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M07 - Deep Learning with PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcGbZ4WDOCS0No2VOUqCG8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulbruffett/python_class/blob/master/M07_Deep_Learning_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMBk_J2x0VOX",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Digits Recognition\n",
        "MNIST is a canonical dataset for machine learning consisting of handwritten digits from 0 - 9 that are 28x28 pixel greyscale images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR8wgjND0Td0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHmoP8HS2V16",
        "colab_type": "text"
      },
      "source": [
        "## Load and plot the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waMcbvfx1AwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.MNIST('../data', train=True, download=True)\n",
        "test_dataset = datasets.MNIST('../data', train=False, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOlvXFiX1VZ4",
        "colab_type": "code",
        "outputId": "653367aa-003c-433c-ec6f-1a6a52073d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "train_dataset.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxfZkVL-1iNY",
        "colab_type": "code",
        "outputId": "04704d47-d8fc-4402-8cca-5dc0f28b9a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "train_dataset.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YGvLvMr1ySt",
        "colab_type": "code",
        "outputId": "27d81a61-9539-4b47-c7d0-977c4e505195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset.data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xjiwWf31z7i",
        "colab_type": "code",
        "outputId": "f99a5e2c-b344-43e1-d1aa-cef16328e8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imgplot = plt.imshow(train_dataset.data[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngrADSRB2IIn/Bziw80r6zfkYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luQMuGLT2Cec",
        "colab_type": "code",
        "outputId": "0d2ee975-77b2-4fea-a05f-a2dfa02ee060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset.targets[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljetxmMO2Ly3",
        "colab_type": "code",
        "outputId": "72b23051-a114-42c8-f1aa-d4b183760185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset.data.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(255, dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivOtPKVR2b7i",
        "colab_type": "text"
      },
      "source": [
        "## Scale and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4KWSGB2S6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_dataset.data / 255.\n",
        "y_train = train_dataset.targets\n",
        "X_test = test_dataset.data / 255.\n",
        "y_test = test_dataset.targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzwv5xV22kr_",
        "colab_type": "code",
        "outputId": "018b35a9-a717-4805-f505-3ca22bc9c122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gwirm4nPMOW",
        "colab_type": "text"
      },
      "source": [
        "## Create the model\n",
        "We're building a simple, dense neural network\n",
        "The forward is how the network is traversed, the init defines the actual structure of the neural net."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y35mBdkv3Pz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Quo-K74ACo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(TensorDataset(X_train,y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test,y_test), batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6M9J48j6Qtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DNN()\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e-q2YzvPVUK",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "We'll do 5 epochs, so all of the data will be seen 5 times.  We're going to iterate through the data loaders and train on 64 images at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEnfNoS83ffp",
        "colab_type": "code",
        "outputId": "e30c532e-12d6-4e69-de3e-7a01721b2338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "epochs = 5\n",
        "print_every = 200\n",
        "steps = 0\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for step, (x,y) in enumerate(train_loader):\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "#        x.resize_(x.size()[0], 784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward and backward passes\n",
        "        output = model.forward(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if step % print_every == 0:\n",
        "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
        "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
        "            \n",
        "            running_loss = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5...  Loss: 0.0115\n",
            "Epoch: 1/5...  Loss: 0.8589\n",
            "Epoch: 1/5...  Loss: 0.3832\n",
            "Epoch: 1/5...  Loss: 0.3236\n",
            "Epoch: 1/5...  Loss: 0.2963\n",
            "Epoch: 2/5...  Loss: 0.0012\n",
            "Epoch: 2/5...  Loss: 0.2559\n",
            "Epoch: 2/5...  Loss: 0.2327\n",
            "Epoch: 2/5...  Loss: 0.2121\n",
            "Epoch: 2/5...  Loss: 0.2070\n",
            "Epoch: 3/5...  Loss: 0.0009\n",
            "Epoch: 3/5...  Loss: 0.1809\n",
            "Epoch: 3/5...  Loss: 0.1726\n",
            "Epoch: 3/5...  Loss: 0.1719\n",
            "Epoch: 3/5...  Loss: 0.1547\n",
            "Epoch: 4/5...  Loss: 0.0006\n",
            "Epoch: 4/5...  Loss: 0.1416\n",
            "Epoch: 4/5...  Loss: 0.1473\n",
            "Epoch: 4/5...  Loss: 0.1260\n",
            "Epoch: 4/5...  Loss: 0.1308\n",
            "Epoch: 5/5...  Loss: 0.0009\n",
            "Epoch: 5/5...  Loss: 0.1230\n",
            "Epoch: 5/5...  Loss: 0.1180\n",
            "Epoch: 5/5...  Loss: 0.1107\n",
            "Epoch: 5/5...  Loss: 0.1104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNSt6JMSL5zX",
        "colab_type": "text"
      },
      "source": [
        "torch.nn defines nn.Module classes, torch nn.functional uses a functional (stateless) approach.\n",
        "To dig a bit deeper: nn.Modules are defined as Python classes and have attributes, e.g. a nn.Conv2d module will have some internal attributes like self.weight. F.conv2d however just defines the operation and needs all arguments to be passed (including the weights and bias). Internally the modules will usually call their functional counterpart in the forward method somewhere."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18eKoiu72tdT",
        "colab_type": "code",
        "outputId": "6f92c29d-6888-4947-cb1b-679271b2ca4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1156, Accuracy: 9662/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHe8OOn9OEcH",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy metrics\n",
        "Let's break down our accuracy function here into steps, because some of it probably is confusing.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbU358tMrN-",
        "colab_type": "text"
      },
      "source": [
        "###First, let's make a prediction\n",
        "\n",
        "We have to reshape the tensor to look like a batch.  The model was trained on data of batch_size x img_height x img_width; 64x28x28 data.  Now we're feeding it one sample that's 28x28, it's saying \"I'm missing a dimension here\", so we need to feed it a 'batch' of 1x28x28 to get a prediction.\n",
        "\n",
        "Reshape of -1 says \"make this as long or short as needed, based on the other dimensions\", so here we're saying \"reshape the matrix to 28x28 and as many batches as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB7DC_vmJ1eZ",
        "colab_type": "code",
        "outputId": "700e2e34-cbca-4c41-fa5c-ecbd7951d650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  print(model(X_test[0].reshape(-1,28,28)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.2341e+01, -1.6217e+01, -8.3700e+00, -5.9455e+00, -1.7039e+01,\n",
            "         -1.1560e+01, -2.1767e+01, -2.8979e-03, -1.1646e+01, -1.0740e+01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-x-b0_cJ_y5",
        "colab_type": "code",
        "outputId": "b45d14e1-77eb-4406-b42d-4cdbb80fd0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  print(torch.max(model(X_test[10].reshape(-1,28,28)),1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([-0.0009]),\n",
            "indices=tensor([0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRVRMgE3KaK5",
        "colab_type": "code",
        "outputId": "701eed35-77fe-4e1b-c1f8-ac350bd4a42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#checks out\n",
        "y_test[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfS8Qx4kK0GL",
        "colab_type": "code",
        "outputId": "0e04a978-ce5a-4373-e71a-7f7c44e5dc8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#now let's look at the loss function, this is getting the cumulative model error\n",
        "F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.4311699867248535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgUjUTxhOdDA",
        "colab_type": "code",
        "outputId": "bbe09f8c-8fa7-48cc-b025-ead2e1e99aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#this is the prediction, similar to what I did with torch.max\n",
        "output.argmax(dim=1, keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [4],\n",
              "        [0],\n",
              "        [7],\n",
              "        [8],\n",
              "        [4],\n",
              "        [1],\n",
              "        [9],\n",
              "        [5],\n",
              "        [1],\n",
              "        [4],\n",
              "        [1],\n",
              "        [0],\n",
              "        [6],\n",
              "        [9],\n",
              "        [3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ipHe3BOmem",
        "colab_type": "code",
        "outputId": "ee6e3534-5ce7-479b-a716-ba471c6b5bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#this is comparing the predictions to the actuals to get the accuracy score\n",
        "pred.eq(target.view_as(pred)).sum().item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P49wYDsPdIa",
        "colab_type": "text"
      },
      "source": [
        "# Fashion MNIST\n",
        "A more challenging example, since a trivial neural net got 97% at MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p9g967mOryu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transforms.ToTensor())\n",
        "trainset.data = trainset.data/255.\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transforms.ToTensor())\n",
        "testset.data = testset.data/255.\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LPf5R1kTjsZ",
        "colab_type": "code",
        "outputId": "cdb42468-320f-4c02-de61-89beec295af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainset.data.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVL3Cl4COwV9",
        "colab_type": "code",
        "outputId": "c4c9a3eb-567a-45cb-8460-543f3167380b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imgplot = plt.imshow(trainset.data[55])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF66tuAqPyLM",
        "colab_type": "code",
        "outputId": "c3b1ca85-6acb-422a-8d1d-0832c27b692f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainset.targets.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQZj2dewRZLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class conv_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out([1,28,28])\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        return self.fc(conv_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YyHizGtZA_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = conv_net()\n",
        "#model = DNN()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTYJVLA8QCUW",
        "colab_type": "code",
        "outputId": "283a0bad-6e88-4c89-de6f-8199e87ee2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "epochs = 5\n",
        "print_every = 200\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for step, (x,y) in enumerate(trainloader):\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "#        x.resize_(x.size()[0], 784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward and backward passes\n",
        "        output = model.forward(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if step > 1:\n",
        "          if step % print_every == 0:\n",
        "              print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
        "                    \"Loss: {:.4f}\".format(running_loss/print_every))\n",
        "              \n",
        "              running_loss = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5...  Loss: 1.2823\n",
            "Epoch: 1/5...  Loss: 0.9596\n",
            "Epoch: 1/5...  Loss: 0.8923\n",
            "Epoch: 1/5...  Loss: 0.8569\n",
            "Epoch: 2/5...  Loss: 0.8237\n",
            "Epoch: 2/5...  Loss: 0.7978\n",
            "Epoch: 2/5...  Loss: 0.7979\n",
            "Epoch: 2/5...  Loss: 0.7779\n",
            "Epoch: 3/5...  Loss: 0.7561\n",
            "Epoch: 3/5...  Loss: 0.7465\n",
            "Epoch: 3/5...  Loss: 0.7443\n",
            "Epoch: 3/5...  Loss: 0.7490\n",
            "Epoch: 4/5...  Loss: 0.7130\n",
            "Epoch: 4/5...  Loss: 0.7119\n",
            "Epoch: 4/5...  Loss: 0.7061\n",
            "Epoch: 4/5...  Loss: 0.7046\n",
            "Epoch: 5/5...  Loss: 0.6775\n",
            "Epoch: 5/5...  Loss: 0.6654\n",
            "Epoch: 5/5...  Loss: 0.6744\n",
            "Epoch: 5/5...  Loss: 0.6807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIfKT8SVQHdF",
        "colab_type": "code",
        "outputId": "c2cc2070-a00b-4ea2-8cf9-5d80659e2528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in testloader:\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(testloader.dataset)\n",
        "\n",
        "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(testloader.dataset),\n",
        "    100. * correct / len(testloader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7860, Accuracy: 6955/10000 (70%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZYshmVkRTRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}